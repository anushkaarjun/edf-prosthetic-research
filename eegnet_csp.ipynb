# Approach : EEGNET + CSP (2 class)
import os, glob
import numpy as np
import mne
import torch
import torch.nn as nn
import torch.optim as optim
from torch.utils.data import Dataset, DataLoader
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import LabelEncoder
from sklearn.utils.class_weight import compute_class_weight
from mne.decoding import CSP
import matplotlib.pyplot as plt

DEVICE = torch.device("cuda" if torch.cuda.is_available() else "cpu")
BASE_PATH = "/Users/anushkaarjun/Desktop/Outside of School/Prosethic Research Data/files 2"  # <-- change this
MAX_SUBJECTS = 109
FREQ_LOW, FREQ_HIGH = 8, 30
TARGET_SFREQ = 128
TMIN, TMAX = 0, 4
BATCH_SIZE = 32
N_CSP_COMPONENTS = 8
EPOCHS = 20
LR = 1e-3

# -------------------------
# EEGNet for CSP (temporal kernel=1)
# -------------------------
class EEGNet(nn.Module):
    def __init__(self, n_channels, n_samples, n_classes):
        super().__init__()
        self.conv1 = nn.Conv2d(1, 16, (1,1))  # temporal kernel=1 for CSP input
        self.bn1 = nn.BatchNorm2d(16)
        self.depthwise = nn.Conv2d(16, 32, (n_channels,1), groups=16)
        self.bn2 = nn.BatchNorm2d(32)
        self.pool = nn.AvgPool2d((1,1))
        self.drop = nn.Dropout(0.25)
        self.separable = nn.Conv2d(32, 32, (1,1), groups=32)
        self.bn3 = nn.BatchNorm2d(32)
        self.fc = nn.Linear(32*1, n_classes)  # 32*1 because width=1

    def forward(self, x):
        x = torch.relu(self.bn1(self.conv1(x)))
        x = torch.relu(self.bn2(self.depthwise(x)))
        x = self.pool(x)
        x = self.drop(x)
        x = torch.relu(self.bn3(self.separable(x)))
        x = x.flatten(1)
        return self.fc(x)

# -------------------------
# Dataset
# -------------------------
class EEGDataset(Dataset):
    def __init__(self, X, y):
        self.X = X.astype(np.float32)
        self.y = y.astype(np.int64)
    def __len__(self):
        return len(self.X)
    def __getitem__(self, idx):
        x = self.X[idx][np.newaxis,:,:]  # 1 x channels x samples
        y = self.y[idx]
        return torch.tensor(x), torch.tensor(y)

# -------------------------
# Load & preprocess
# -------------------------
subject_data = {}
for subj_idx in range(1, MAX_SUBJECTS+1):
    subj = f"S{subj_idx:03d}"
    print(f"\nProcessing {subj}")
    files = sorted(glob.glob(os.path.join(BASE_PATH, subj, "*.edf")))
    X_list, y_list = [], []
    for file in files:
        raw = mne.io.read_raw_edf(file, preload=True, verbose=False)
        raw.filter(FREQ_LOW, FREQ_HIGH, verbose=False)
        if raw.info['sfreq'] != TARGET_SFREQ:
            raw.resample(TARGET_SFREQ)
        events, event_id = mne.events_from_annotations(raw, verbose=False)
        if len(events)==0: continue
        epochs = mne.Epochs(raw, events, tmin=TMIN, tmax=TMAX, baseline=None, preload=True, verbose=False)
        if len(epochs)==0: continue
        X = epochs.get_data()
        y_raw = epochs.events[:,-1]
        valid_idx = []
        y_bin = []
        for idx,val in enumerate(y_raw):
            if val==2:  # left
                y_bin.append(0)
                valid_idx.append(idx)
            elif val==3:  # right
                y_bin.append(1)
                valid_idx.append(idx)
        if len(valid_idx)==0: continue
        X_list.append(X[valid_idx])
        y_list += y_bin
    if len(X_list)>0:
        X_subj = np.concatenate(X_list, axis=0)
        subject_data[subj] = {"X": X_subj, "y": np.array(y_list)}
        print(f"{subj}: {X_subj.shape[0]} epochs")
    else:
        print(f"{subj}: No usable epochs")

# -------------------------
# Train per-subject EEGNet + CSP
# -------------------------
subject_results = {}
for subj, data in subject_data.items():
    print(f"\nTraining {subj}")
    X, y = data['X'], data['y']
    X_train, X_temp, y_train, y_temp = train_test_split(X, y, test_size=0.4, stratify=y, random_state=42)
    X_val, X_test, y_val, y_test = train_test_split(X_temp, y_temp, test_size=0.5, stratify=y_temp, random_state=42)

    csp = CSP(n_components=N_CSP_COMPONENTS, reg=None, log=True, norm_trace=False)
    X_train_csp = csp.fit_transform(X_train, y_train)
    X_val_csp   = csp.transform(X_val)
    X_test_csp  = csp.transform(X_test)

    # reshape for EEGNet: (samples, channels, width)
    X_train_csp = X_train_csp[:,:,np.newaxis]
    X_val_csp   = X_val_csp[:,:,np.newaxis]
    X_test_csp  = X_test_csp[:,:,np.newaxis]

    train_ds = EEGDataset(X_train_csp, y_train)
    val_ds   = EEGDataset(X_val_csp, y_val)
    test_ds  = EEGDataset(X_test_csp, y_test)
    train_loader = DataLoader(train_ds, batch_size=BATCH_SIZE, shuffle=True)
    val_loader   = DataLoader(val_ds, batch_size=BATCH_SIZE, shuffle=False)
    test_loader  = DataLoader(test_ds, batch_size=BATCH_SIZE, shuffle=False)

    class_weights = compute_class_weight('balanced', classes=np.unique(y_train), y=y_train)
    class_weights = torch.tensor(class_weights, dtype=torch.float32).to(DEVICE)

    n_channels = X_train_csp.shape[1]
    n_samples  = X_train_csp.shape[2]
    model = EEGNet(n_channels, n_samples, n_classes=2).to(DEVICE)
    criterion = nn.CrossEntropyLoss(weight=class_weights)
    optimizer = optim.Adam(model.parameters(), lr=LR)

    best_val_acc = 0
    best_state = None
    for epoch in range(EPOCHS):
        model.train()
        for xb,yb in train_loader:
            xb,yb=xb.to(DEVICE),yb.to(DEVICE)
            optimizer.zero_grad()
            loss=criterion(model(xb),yb)
            loss.backward()
            optimizer.step()
        # Validation
        model.eval()
        correct,total=0,0
        with torch.no_grad():
            for xb,yb in val_loader:
                xb,yb=xb.to(DEVICE),yb.to(DEVICE)
                preds=model(xb).argmax(dim=1)
                correct+=(preds==yb).sum().item()
                total+=yb.size(0)
        val_acc = correct/total
        if val_acc>best_val_acc:
            best_val_acc=val_acc
            best_state=model.state_dict()
        print(f"Epoch {epoch+1}/{EPOCHS}, Val Accuracy: {val_acc*100:.2f}%")

    model.load_state_dict(best_state)
    # Evaluate
    def evaluate(loader):
        model.eval()
        correct,total=0,0
        with torch.no_grad():
            for xb,yb in loader:
                xb,yb=xb.to(DEVICE),yb.to(DEVICE)
                preds=model(xb).argmax(dim=1)
                correct+=(preds==yb).sum().item()
                total+=yb.size(0)
        return correct/total
    train_acc = evaluate(train_loader)
    val_acc   = evaluate(val_loader)
    test_acc  = evaluate(test_loader)
    print(f"{subj} -> Train: {train_acc*100:.2f}%, Val: {val_acc*100:.2f}%, Test: {test_acc*100:.2f}%")
    subject_results[subj] = {"train_acc":train_acc, "val_acc":val_acc, "test_acc":test_acc}

# -------------------------
# Plot per-subject
# -------------------------
subjects = list(subject_results.keys())
train_accs = [subject_results[s]['train_acc']*100 for s in subjects]
val_accs   = [subject_results[s]['val_acc']*100 for s in subjects]
test_accs  = [subject_results[s]['test_acc']*100 for s in subjects]

x = np.arange(len(subjects))
width = 0.25
plt.figure(figsize=(12,5))
plt.bar(x-width, train_accs,width,label='Train')
plt.bar(x, val_accs,width,label='Validation')
plt.bar(x+width, test_accs,width,label='Test')
plt.xticks(x, subjects)
plt.ylabel("Accuracy (%)")
plt.title("Per-subject EEGNet + CSP Accuracy (2-class)")
plt.legend()
plt.show()

import numpy as np

# =========================
# Overall Accuracy Across Subjects
# =========================
all_train, all_val, all_test = [], [], []

print("\n" + "="*60)
print("FINAL RESULTS ACROSS SUBJECTS")
print("="*60)

for subj, res in subject_results.items():
    train_acc = res["train_acc"] * 100
    val_acc   = res["val_acc"] * 100
    test_acc  = res["test_acc"] * 100
    
    all_train.append(train_acc)
    all_val.append(val_acc)
    all_test.append(test_acc)
    
    print(f"Subject {subj}: Train={train_acc:.2f}%, Val={val_acc:.2f}%, Test={test_acc:.2f}%")

print("-"*60)
print(f"Average Train Accuracy: {np.mean(all_train):.2f}%")
print(f"Average Validation Accuracy: {np.mean(all_val):.2f}%")
print(f"Average Test Accuracy: {np.mean(all_test):.2f}%")
print("="*60)

